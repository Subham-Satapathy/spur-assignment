# AI Chat Support Agent - Modular Monolith

A production-ready AI-powered customer support chat system built with TypeScript, Express, NeonDB (serverless PostgreSQL), and Drizzle ORM using a **Modular Monolith architecture**.

## ğŸ—ï¸ Architecture Overview

The application is structured into **6 independent modules**:

```
src/
â”œâ”€â”€ modules/
â”‚   â”œâ”€â”€ api/            # HTTP routes, validation, error handling
â”‚   â”œâ”€â”€ chat/           # Orchestration layer - coordinates operations
â”‚   â”œâ”€â”€ conversation/   # Conversation & message persistence  
â”‚   â”œâ”€â”€ llm/            # LLM provider (OpenAI)
â”‚   â”œâ”€â”€ knowledge/      # FAQ/domain knowledge management
â”‚   â””â”€â”€ messaging/      # Event bus for cross-module communication
â”œâ”€â”€ shared/
â”‚   â”œâ”€â”€ config/         # Environment configuration
â”‚   â”œâ”€â”€ database/       # NeonDB connection & Drizzle schema
â”‚   â”œâ”€â”€ errors/         # Custom error classes
â”‚   â”œâ”€â”€ logger/         # Winston structured logging
â”‚   â””â”€â”€ types/          # Shared TypeScript interfaces
â”œâ”€â”€ scripts/            # Database seed & validation scripts
â”œâ”€â”€ app.ts              # Application bootstrap & dependency injection
â””â”€â”€ server.ts           # HTTP server entry point
```

### Key Technologies

- **Backend**: Node.js 18+, TypeScript (strict mode), Express 4.18
- **Database**: NeonDB (serverless PostgreSQL) with Drizzle ORM 0.45
- **LLM Provider**: OpenAI (GPT-4)  
- **Frontend**: Vanilla JavaScript chat UI
- **Validation**: Zod schemas
- **Logging**: Winston

### Architectural Patterns

- **Dependency Injection**: Constructor injection for testability
- **Repository Pattern**: Data access layer abstraction
- **Event-Driven**: Internal event bus for module decoupling
- **Provider Pattern**: Swappable LLM implementations

## ğŸš€ Features

- âœ… Real LLM Integration (OpenAI GPT-4)
- âœ… Serverless PostgreSQL (NeonDB) with Drizzle ORM
- âœ… Conversation persistence with full history
- âœ… Knowledge base for context-aware responses
- âœ… Clean chat UI (no framework overhead)
- âœ… Robust error handling & validation
- âœ… Health checks for database & LLM
- âœ… Structured logging
- âœ… Full TypeScript type safety

## ğŸ“‹ Prerequisites

- **Node.js** 18+ (LTS recommended)
- **npm** or yarn
- **NeonDB account** (free tier available at [neon.tech](https://neon.tech))
- **OpenAI API key** ([platform.openai.com](https://platform.openai.com))

## ğŸ› ï¸ Quick Start

### 1. Install Dependencies

```bash
npm install
```

### 2. Set up NeonDB Database

1. Create account at [neon.tech](https://neon.tech)
2. Create new project in NeonDB console
3. Copy connection string (format: `postgresql://user:password@ep-xxx.region.aws.neon.tech/dbname?sslmode=require`)

### 3. Configure Environment

Copy the example environment file:

```bash
cp .env.example .env
```

Edit `.env` with your credentials:

```env
# Server
NODE_ENV=development
PORT=3000

# Database (NeonDB)
DATABASE_URL=postgresql://your-user:your-password@ep-xxx.region.aws.neon.tech/your-db?sslmode=require

# OpenAI
OPENAI_API_KEY=sk-your-actual-key-here
OPENAI_MODEL=gpt-4
```

### 4. Initialize Database Schema

Push the Drizzle schema to NeonDB:

```bash
npm run db:push
```

This creates the following tables:
- `conversations` - Chat session tracking
- `messages` - Message history
- `knowledge_entries` - FAQ/knowledge base

### 5. Seed Knowledge Base

Populate the database with sample FAQ data:

```bash
npm run db:seed
```

This adds FAQs for:
- Shipping policies
- Returns & refunds
- Payment methods
- Support hours

### 6. Build & Start

Build TypeScript:

```bash
npm run build
```

Start the development server:

```bash
npm run dev
```

Or run in production mode:

```bash
npm start
```

The server will start on `http://localhost:3000`

### 7. Access Chat UI

Open your browser to:

```
http://localhost:3000
```

You'll see the chat interface where you can:
- Ask questions about shipping, returns, payments, etc.
- Get AI-powered responses using your knowledge base
- View conversation history

## ğŸ“š Available Scripts

| Script | Description |
|--------|-------------|
| `npm run dev` | Start development server with hot reload (tsx watch) |
| `npm start` | Start production server |
| `npm run build` | Compile TypeScript to JavaScript |
| `npm run db:generate` | Generate Drizzle migration files from schema |
| `npm run db:push` | Push schema directly to NeonDB (development) |
| `npm run db:migrate` | Apply migrations (production) |
| `npm run db:seed` | Seed knowledge base with FAQ data |

## ğŸ”Œ API Endpoints

### Health Check

```http
GET /health
```

Response:
```json
{
  "status": "healthy",
  "timestamp": "2024-01-15T10:30:00.000Z",
  "uptime": 123.45,
  "services": {
    "database": "connected",
    "llm": "connected"
  }
}
```

### Create Conversation

```http
POST /api/conversations
```

Response:
```json
{
  "conversationId": "550e8400-e29b-41d4-a716-446655440000"
}
```

### Send Message

```http
POST /api/conversations/:conversationId/messages
Content-Type: application/json

{
  "message": "What is your return policy?"
}
```

Response:
```json
{
  "messageId": "660e8400-e29b-41d4-a716-446655440000",
  "reply": "We accept returns within 30 days of delivery...",
  "processingTime": 1234
}
```

### Get Conversation History

```http
GET /api/conversations/:conversationId/messages
```

Response:
```json
{
  "messages": [
    {
      "id": "msg-1",
      "text": "What is your return policy?",
      "sender": "user",
      "createdAt": "2024-01-15T10:30:00.000Z"
    },
    {
      "id": "msg-2",
      "text": "We accept returns within 30 days...",
      "sender": "assistant",
      "createdAt": "2024-01-15T10:30:02.000Z"
    }
  ]
}
```

## ğŸ—‚ï¸ Database Schema (Drizzle)

### conversations

| Column | Type | Description |
|--------|------|-------------|
| id | uuid | Primary key |
| status | varchar | 'active' or 'closed' |
| metadata | jsonb | Custom metadata |
| created_at | timestamp | Creation time |
| updated_at | timestamp | Last update time |

### messages

| Column | Type | Description |
|--------|------|-------------|
| id | uuid | Primary key |
| conversation_id | uuid | Foreign key to conversations |
| text | text | Message content |
| sender | varchar | 'user' or 'assistant' |
| metadata | jsonb | Custom metadata |
| created_at | timestamp | Creation time |

### knowledge_entries

| Column | Type | Description |
|--------|------|-------------|
| id | uuid | Primary key |
| category | varchar | FAQ category |
| title | varchar | Entry title |
| content | text | Entry content |
| priority | integer | Display priority |
| is_active | boolean | Active status |
| created_at | timestamp | Creation time |
| updated_at | timestamp | Last update time |

## ğŸ§ª Testing

Test the API with curl:

```bash
# Health check
curl http://localhost:3000/health

# Create conversation
CONV_ID=$(curl -X POST http://localhost:3000/api/conversations | jq -r '.conversationId')

# Send message
curl -X POST http://localhost:3000/api/conversations/$CONV_ID/messages \
  -H "Content-Type: application/json" \
  -d '{"message":"What is your shipping policy?"}'

# Get history
curl http://localhost:3000/api/conversations/$CONV_ID/messages
```

## ğŸ”§ Configuration

### Environment Variables

| Variable | Required | Default | Description |
|----------|----------|---------|-------------|
| `NODE_ENV` | No | `development` | Environment mode |
| `PORT` | No | `3000` | Server port |
| `DATABASE_URL` | Yes | - | NeonDB connection string |
| `OPENAI_API_KEY` | Yes | - | OpenAI API key |
| `OPENAI_MODEL` | No | `gpt-4` | OpenAI model |
| `LOG_LEVEL` | No | `info` | Winston log level |

## ğŸ“– Module Documentation

### Chat Module (`src/modules/chat`)

Orchestration layer that coordinates:
- Conversation creation & management
- Message routing between user and LLM
- Knowledge base retrieval for context
- Event publishing for analytics

### LLM Module (`src/modules/llm`)

OpenAI integration supporting:
- **GPT-4**, GPT-3.5 Turbo

Implements:
- System prompt building
- Conversation context formatting
- Error handling & retries
- Health checks

### Conversation Module (`src/modules/conversation`)

Manages:
- Conversation lifecycle (create, update, close)
- Message persistence
- Conversation history retrieval
- Repository pattern for data access

### Knowledge Module (`src/modules/knowledge`)

Features:
- FAQ storage & retrieval
- Category-based organization
- Priority-based sorting
- Active/inactive entry management

### Messaging Module (`src/modules/messaging`)

Event bus for:
- `MESSAGE_RECEIVED` - User message logged
- `MESSAGE_SENT` - AI response sent
- `LLM_REQUEST_FAILED` - LLM error occurred
- `CONVERSATION_CREATED` - New conversation started
- `CONVERSATION_CLOSED` - Conversation ended

### API Module (`src/modules/api`)

HTTP layer with:
- Express routes & middleware
- Zod validation
- Error handling
- CORS configuration

## ğŸš€ Deployment

### NeonDB Production

1. Create production database in NeonDB
2. Update `DATABASE_URL` in production environment
3. Run migrations:
   ```bash
   npm run db:migrate
   ```
4. Seed knowledge base:
   ```bash
   npm run db:seed
   ```

### Environment Setup

Set production environment variables:

```bash
export NODE_ENV=production
export PORT=3000
export DATABASE_URL=postgresql://...
export OPENAI_API_KEY=sk-...
```

### Start Production Server

```bash
npm run build
npm start
```

## ğŸ“ License

MIT

## ğŸ¤ Contributing

Pull requests welcome! Please ensure:
- TypeScript compiles without errors
- Follow existing code style
- Add tests for new features

## ğŸ“§ Support

For issues or questions, open a GitHub issue.

---

**Built with â¤ï¸ using Modular Monolith Architecture**
